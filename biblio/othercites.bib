@online{Stats,
	title = {Magnetic resonance imaging scanners in Italy 2000-2016 {\textbar} Statistic},
	url = {https://www.statista.com/statistics/557511/magnetic-resonance-imaging-scanners-in-italy/},
	abstract = {This statistic displays the total number of magnetic resonance imaging ({MRI}) scanners in Italy from 2000 to 2016. The number of {MRI} scanners has increased over the 17 year period observed to 1,722 units in 2016.},
	titleaddon = {Statista},
	urldate = {2019-05-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Sergey\\Zotero\\storage\\PQGYT2UN\\magnetic-resonance-imaging-scanners-in-italy.html:text/html}
}



@online{noauthor_zotero_nodate,
	title = {Zotero {\textbar} Your personal research assistant},
	url = {https://www.zotero.org/},
	urldate = {2019-05-28},
	file = {Zotero | Your personal research assistant:C\:\\Users\\Sergey\\Zotero\\storage\\7YVVLDL6\\www.zotero.org.html:text/html}
}

@online{noauthor_statista_nodate,
	title = {Statista - The Statistics Portal},
	url = {https://www.statista.com/search/},
	abstract = {Find statistics, consumer survey results and industry studies
                    from over 22,500 sources on over 60,000 topics on the internet's
                    leading statistics database},
	titleaddon = {Statista},
	urldate = {2019-05-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Sergey\\Zotero\\storage\\XEKG7LS9\\search.html:text/html}
}

@online{noauthor_statista_nodate-1,
	title = {Statista - The Statistics Portal},
	url = {https://www.statista.com/search/},
	abstract = {Find statistics, consumer survey results and industry studies
                    from over 22,500 sources on over 60,000 topics on the internet's
                    leading statistics database},
	titleaddon = {Statista},
	urldate = {2019-05-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Sergey\\Zotero\\storage\\QYECCWQ5\\search.html:text/html}
}

@online{noauthor_magnetic_nodate,
	title = {Magnetic resonance imaging scanners in Italy 2000-2016 {\textbar} Statistic},
	url = {https://www.statista.com/statistics/557511/magnetic-resonance-imaging-scanners-in-italy/},
	abstract = {This statistic displays the total number of magnetic resonance imaging ({MRI}) scanners in Italy from 2000 to 2016. The number of {MRI} scanners has increased over the 17 year period observed to 1,722 units in 2016.},
	titleaddon = {Statista},
	urldate = {2019-05-28},
	langid = {english},
	file = {Snapshot:C\:\\Users\\Sergey\\Zotero\\storage\\PQGYT2UN\\magnetic-resonance-imaging-scanners-in-italy.html:text/html}
}

@article{xu_weakly_2014,
	title = {Weakly supervised histopathology cancer image segmentation and classification},
	volume = {18},
	issn = {1361-8415},
	url = {http://www.sciencedirect.com/science/article/pii/S1361841514000188},
	doi = {10.1016/j.media.2014.01.010},
	pages = {591--604},
	number = {3},
	journaltitle = {Medical Image Analysis},
	shortjournal = {Medical Image Analysis},
	author = {Xu, Yan and Zhu, Jun-Yan and Chang, Eric I-Chao and Lai, Maode and Tu, Zhuowen},
	urldate = {2019-05-29},
	date = {2014-04-01},
	keywords = {Classification, Clustering, Histopathology image, Image segmentation, Multiple instance learning},
	file = {ScienceDirect Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\WXXR8ZKE\\Xu и др. - 2014 - Weakly supervised histopathology cancer image segm.pdf:application/pdf;ScienceDirect Snapshot:C\:\\Users\\Sergey\\Zotero\\storage\\3352N288\\S1361841514000188.html:text/html}
}

@article{zhan_automatic_2015,
	title = {Automatic method for white matter lesion segmentation based on T1-fluid-attenuated inversion recovery images},
	volume = {9},
	issn = {1751-9632},
	doi = {10.1049/iet-cvi.2014.0121},
	pages = {447--455},
	number = {4},
	journaltitle = {{IET} Computer Vision},
	author = {Zhan, T. and Zhan, Y. and Liu, Z. and Xiao, L. and Wei, Z.},
	date = {2015},
	keywords = {automatic white matter lesion segmentation, biological tissues, biomedical {MRI}, brain, brain tissue segmentation method, cerebrospinal fluid, Gaussian distribution, grey matter, image segmentation, local Gaussian distribution fitting energy, medical image processing, modified level-set technique, {MR} data intensity inhomogeneity, set theory, T1-fluid-attenuated inversion recovery image modality, white matter lesion boundary},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Sergey\\Zotero\\storage\\LVX357RF\\7172647.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\RD4A5K9X\\Zhan и др. - 2015 - Automatic method for white matter lesion segmentat.pdf:application/pdf}
}

@article{jia_constrained_2017,
	title = {Constrained Deep Weak Supervision for Histopathology Image Segmentation},
	volume = {36},
	issn = {0278-0062, 1558-254X},
	url = {http://arxiv.org/abs/1701.00794},
	doi = {10.1109/TMI.2017.2724070},
	pages = {2376--2388},
	number = {11},
	journaltitle = {{IEEE} Transactions on Medical Imaging},
	shortjournal = {{IEEE} Trans. Med. Imaging},
	author = {Jia, Zhipeng and Huang, Xingyi and Chang, Eric I.-Chao and Xu, Yan},
	urldate = {2019-05-30},
	date = {2017-11},
	eprinttype = {arxiv},
	eprint = {1701.00794},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv\:1701.00794 PDF:C\:\\Users\\Sergey\\Zotero\\storage\\9IEIIJRS\\Jia и др. - 2017 - Constrained Deep Weak Supervision for Histopatholo.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sergey\\Zotero\\storage\\RSNLY6QU\\1701.html:text/html}
}

@inproceedings{ben-ari_weakly_2016,
	title = {A weakly labeled approach for breast tissue segmentation and breast density estimation in digital mammography},
	doi = {10.1109/ISBI.2016.7493368},
	eventtitle = {2016 {IEEE} 13th International Symposium on Biomedical Imaging ({ISBI})},
	pages = {722--725},
	booktitle = {2016 {IEEE} 13th International Symposium on Biomedical Imaging ({ISBI})},
	author = {Ben-Ari, R. and Zlotnick, A. and Hashoul, S.},
	date = {2016-04},
	keywords = {Image segmentation, image segmentation, medical image processing, Adaptive parameter setting, average Jaccard spatial similarity coefficient, breast density, breast density classification, Breast tissue, breast tissue segmentation, Estimation, feature extraction, Feature extraction, fibroglandular delineated images, full-field digital mammograms, fuzzy logic, Fuzzy logic, fuzzy-logic module, image classification, mammography, Mammography, segmentation, weakly labeled approach},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Sergey\\Zotero\\storage\\28BAVKSZ\\7493368.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\X6PZ69NJ\\Ben-Ari и др. - 2016 - A weakly labeled approach for breast tissue segmen.pdf:application/pdf}
}

@inproceedings{choukroun_mammogram_2017,
	title = {Mammogram Classification and Abnormality Detection from Nonlocal Labels using Deep Multiple Instance Neural Network},
	doi = {10.2312/vcbm.20171232},
	booktitle = {{VCBM}},
	author = {Choukroun, Yoni and Bakalo, Ran and Ben-Ari, Rami and Akselrod-Ballin, Ayelet and Barkan, Ella and Kisilev, Pavel},
	date = {2017},
	keywords = {Multiple instance learning, Aharonov–Bohm effect, Artificial neural network, Complexity, Convolutional neural network, Deep learning, Emergence, Eurographics, Feature engineering, Internationalization and localization, Machine learning, Mg (editor), Modality (human–computer interaction), Overhead (computing), Programming paradigm, Radiology, Sensitivity and specificity, Sensor, Statistical classification, Supervised learning, Unavailability},
	file = {Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\UPZ3FXKP\\Choukroun и др. - 2017 - Mammogram Classification and Abnormality Detection.pdf:application/pdf}
}

@inproceedings{choukroun_mammogram_2017-1,
	title = {Mammogram Classification and Abnormality Detection from Nonlocal Labels using Deep Multiple Instance Neural Network},
	doi = {10.2312/vcbm.20171232},
	booktitle = {{VCBM}},
	author = {Choukroun, Yoni and Bakalo, Ran and Ben-Ari, Rami and Akselrod-Ballin, Ayelet and Barkan, Ella and Kisilev, Pavel},
	date = {2017},
	keywords = {Multiple instance learning, Aharonov–Bohm effect, Artificial neural network, Complexity, Convolutional neural network, Deep learning, Emergence, Eurographics, Feature engineering, Internationalization and localization, Machine learning, Mg (editor), Modality (human–computer interaction), Overhead (computing), Programming paradigm, Radiology, Sensitivity and specificity, Sensor, Statistical classification, Supervised learning, Unavailability},
	file = {Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\J7S4GE9X\\Choukroun и др. - 2017 - Mammogram Classification and Abnormality Detection.pdf:application/pdf}
}

@article{BRATS_2018,
	title = {Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the {BRATS} Challenge},
	url = {http://arxiv.org/abs/1811.02629},
	journaltitle = {{arXiv}:1811.02629 [cs, stat]},
	author = {Bakas, Spyridon and Reyes, Mauricio and Jakab, Andras and Bauer, Stefan and Rempfler, Markus and Crimi, Alessandro and Shinohara, Russell Takeshi and Berger, Christoph and Ha, Sung Min and Rozycki, Martin and Prastawa, Marcel and Alberts, Esther and Lipkova, Jana and Freymann, John and Kirby, Justin and Bilello, Michel and Fathallah-Shaykh, Hassan and Wiest, Roland and Kirschke, Jan and Wiestler, Benedikt and Colen, Rivka and Kotrotsou, Aikaterini and Lamontagne, Pamela and Marcus, Daniel and Milchenko, Mikhail and Nazeri, Arash and Weber, Marc-Andre and Mahajan, Abhishek and Baid, Ujjwal and Gerstner, Elizabeth and Kwon, Dongjin and Acharya, Gagan and Agarwal, Manu and Alam, Mahbubul and Albiol, Alberto and Albiol, Antonio and Albiol, Francisco J. and Alex, Varghese and Allinson, Nigel and Amorim, Pedro H. A. and Amrutkar, Abhijit and Anand, Ganesh and Andermatt, Simon and Arbel, Tal and Arbelaez, Pablo and Avery, Aaron and Azmat, Muneeza and B., Pranjal and Bai, W. and Banerjee, Subhashis and Barth, Bill and Batchelder, Thomas and Batmanghelich, Kayhan and Battistella, Enzo and Beers, Andrew and Belyaev, Mikhail and Bendszus, Martin and Benson, Eze and Bernal, Jose and Bharath, Halandur Nagaraja and Biros, George and Bisdas, Sotirios and Brown, James and Cabezas, Mariano and Cao, Shilei and Cardoso, Jorge M. and Carver, Eric N. and Casamitjana, Adrià and Castillo, Laura Silvana and Catà, Marcel and Cattin, Philippe and Cerigues, Albert and Chagas, Vinicius S. and Chandra, Siddhartha and Chang, Yi-Ju and Chang, Shiyu and Chang, Ken and Chazalon, Joseph and Chen, Shengcong and Chen, Wei and Chen, Jefferson W. and Chen, Zhaolin and Cheng, Kun and Choudhury, Ahana Roy and Chylla, Roger and Clérigues, Albert and Colleman, Steven and Colmeiro, Ramiro German Rodriguez and Combalia, Marc and Costa, Anthony and Cui, Xiaomeng and Dai, Zhenzhen and Dai, Lutao and Daza, Laura Alexandra and Deutsch, Eric and Ding, Changxing and Dong, Chao and Dong, Shidu and Dudzik, Wojciech and Eaton-Rosen, Zach and Egan, Gary and Escudero, Guilherme and Estienne, Théo and Everson, Richard and Fabrizio, Jonathan and Fan, Yong and Fang, Longwei and Feng, Xue and Ferrante, Enzo and Fidon, Lucas and Fischer, Martin and French, Andrew P. and Fridman, Naomi and Fu, Huan and Fuentes, David and Gao, Yaozong and Gates, Evan and Gering, David and Gholami, Amir and Gierke, Willi and Glocker, Ben and Gong, Mingming and González-Villá, Sandra and Grosges, T. and Guan, Yuanfang and Guo, Sheng and Gupta, Sudeep and Han, Woo-Sup and Han, Il Song and Harmuth, Konstantin and He, Huiguang and Hernández-Sabaté, Aura and Herrmann, Evelyn and Himthani, Naveen and Hsu, Winston and Hsu, Cheyu and Hu, Xiaojun and Hu, Xiaobin and Hu, Yan and Hu, Yifan and Hua, Rui and Huang, Teng-Yi and Huang, Weilin and Van Huffel, Sabine and Huo, Quan and {HV}, Vivek and Iftekharuddin, Khan M. and Isensee, Fabian and Islam, Mobarakol and Jackson, Aaron S. and Jambawalikar, Sachin R. and Jesson, Andrew and Jian, Weijian and Jin, Peter and Jose, V. Jeya Maria and Jungo, Alain and Kainz, B. and Kamnitsas, Konstantinos and Kao, Po-Yu and Karnawat, Ayush and Kellermeier, Thomas and Kermi, Adel and Keutzer, Kurt and Khadir, Mohamed Tarek and Khened, Mahendra and Kickingereder, Philipp and Kim, Geena and King, Nik and Knapp, Haley and Knecht, Urspeter and Kohli, Lisa and Kong, Deren and Kong, Xiangmao and Koppers, Simon and Kori, Avinash and Krishnamurthi, Ganapathy and Krivov, Egor and Kumar, Piyush and Kushibar, Kaisar and Lachinov, Dmitrii and Lambrou, Tryphon and Lee, Joon and Lee, Chengen and Lee, Yuehchou and Lee, M. and Lefkovits, Szidonia and Lefkovits, Laszlo and Levitt, James and Li, Tengfei and Li, Hongwei and Li, Wenqi and Li, Hongyang and Li, Xiaochuan and Li, Yuexiang and Li, Heng and Li, Zhenye and Li, Xiaoyu and Li, Zeju and Li, {XiaoGang} and Li, Wenqi and Lin, Zheng-Shen and Lin, Fengming and Lio, Pietro and Liu, Chang and Liu, Boqiang and Liu, Xiang and Liu, Mingyuan and Liu, Ju and Liu, Luyan and Llado, Xavier and Lopez, Marc Moreno and Lorenzo, Pablo Ribalta and Lu, Zhentai and Luo, Lin and Luo, Zhigang and Ma, Jun and Ma, Kai and Mackie, Thomas and Madabushi, Anant and Mahmoudi, Issam and Maier-Hein, Klaus H. and Maji, Pradipta and Mammen, C. P. and Mang, Andreas and Manjunath, B. S. and Marcinkiewicz, Michal and {McDonagh}, S. and {McKenna}, Stephen and {McKinley}, Richard and Mehl, Miriam and Mehta, Sachin and Mehta, Raghav and Meier, Raphael and Meinel, Christoph and Merhof, Dorit and Meyer, Craig and Miller, Robert and Mitra, Sushmita and Moiyadi, Aliasgar and Molina-Garcia, David and Monteiro, Miguel A. B. and Mrukwa, Grzegorz and Myronenko, Andriy and Nalepa, Jakub and Ngo, Thuyen and Nie, Dong and Ning, Holly and Niu, Chen and Nuechterlein, Nicholas K. and Oermann, Eric and Oliveira, Arlindo and Oliveira, Diego D. C. and Oliver, Arnau and Osman, Alexander F. I. and Ou, Yu-Nian and Ourselin, Sebastien and Paragios, Nikos and Park, Moo Sung and Paschke, Brad and Pauloski, J. Gregory and Pawar, Kamlesh and Pawlowski, Nick and Pei, Linmin and Peng, Suting and Pereira, Silvio M. and Perez-Beteta, Julian and Perez-Garcia, Victor M. and Pezold, Simon and Pham, Bao and Phophalia, Ashish and Piella, Gemma and Pillai, G. N. and Piraud, Marie and Pisov, Maxim and Popli, Anmol and Pound, Michael P. and Pourreza, Reza and Prasanna, Prateek and Prkovska, Vesna and Pridmore, Tony P. and Puch, Santi and Puybareau, Élodie and Qian, Buyue and Qiao, Xu and Rajchl, Martin and Rane, Swapnil and Rebsamen, Michael and Ren, Hongliang and Ren, Xuhua and Revanuru, Karthik and Rezaei, Mina and Rippel, Oliver and Rivera, Luis Carlos and Robert, Charlotte and Rosen, Bruce and Rueckert, Daniel and Safwan, Mohammed and Salem, Mostafa and Salvi, Joaquim and Sanchez, Irina and Sánchez, Irina and Santos, Heitor M. and Sartor, Emmett and Schellingerhout, Dawid and Scheufele, Klaudius and Scott, Matthew R. and Scussel, Artur A. and Sedlar, Sara and Serrano-Rubio, Juan Pablo and Shah, N. Jon and Shah, Nameetha and Shaikh, Mazhar and Shankar, B. Uma and Shboul, Zeina and Shen, Haipeng and Shen, Dinggang and Shen, Linlin and Shen, Haocheng and Shenoy, Varun and Shi, Feng and Shin, Hyung Eun and Shu, Hai and Sima, Diana and Sinclair, M. and Smedby, Orjan and Snyder, James M. and Soltaninejad, Mohammadreza and Song, Guidong and Soni, Mehul and Stawiaski, Jean and Subramanian, Shashank and Sun, Li and Sun, Roger and Sun, Jiawei and Sun, Kay and Sun, Yu and Sun, Guoxia and Sun, Shuang and Suter, Yannick R. and Szilagyi, Laszlo and Talbar, Sanjay and Tao, Dacheng and Tao, Dacheng and Teng, Zhongzhao and Thakur, Siddhesh and Thakur, Meenakshi H. and Tharakan, Sameer and Tiwari, Pallavi and Tochon, Guillaume and Tran, Tuan and Tsai, Yuhsiang M. and Tseng, Kuan-Lun and Tuan, Tran Anh and Turlapov, Vadim and Tustison, Nicholas and Vakalopoulou, Maria and Valverde, Sergi and Vanguri, Rami and Vasiliev, Evgeny and Ventura, Jonathan and Vera, Luis and Vercauteren, Tom and Verrastro, C. A. and Vidyaratne, Lasitha and Vilaplana, Veronica and Vivekanandan, Ajeet and Wang, Guotai and Wang, Qian and Wang, Chiatse J. and Wang, Weichung and Wang, Duo and Wang, Ruixuan and Wang, Yuanyuan and Wang, Chunliang and Wang, Guotai and Wen, Ning and Wen, Xin and Weninger, Leon and Wick, Wolfgang and Wu, Shaocheng and Wu, Qiang and Wu, Yihong and Xia, Yong and Xu, Yanwu and Xu, Xiaowen and Xu, Peiyuan and Yang, Tsai-Ling and Yang, Xiaoping and Yang, Hao-Yu and Yang, Junlin and Yang, Haojin and Yang, Guang and Yao, Hongdou and Ye, Xujiong and Yin, Changchang and Young-Moxon, Brett and Yu, Jinhua and Yue, Xiangyu and Zhang, Songtao and Zhang, Angela and Zhang, Kun and Zhang, Xuejie and Zhang, Lichi and Zhang, Xiaoyue and Zhang, Yazhuo and Zhang, Lei and Zhang, Jianguo and Zhang, Xiang and Zhang, Tianhao and Zhao, Sicheng and Zhao, Yu and Zhao, Xiaomei and Zhao, Liang and Zheng, Yefeng and Zhong, Liming and Zhou, Chenhong and Zhou, Xiaobing and Zhou, Fan and Zhu, Hongtu and Zhu, Jin and Zhuge, Ying and Zong, Weiwei and Kalpathy-Cramer, Jayashree and Farahani, Keyvan and Davatzikos, Christos and van Leemput, Koen and Menze, Bjoern},
	urldate = {2019-05-30},
	date = {2018-11-05},
	eprinttype = {arxiv},
	eprint = {1811.02629},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv\:1811.02629 PDF:C\:\\Users\\Sergey\\Zotero\\storage\\5VVINRI2\\Bakas и др. - 2018 - Identifying the Best Machine Learning Algorithms f.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Sergey\\Zotero\\storage\\A8GUIKZT\\1811.html:text/html}
}

@inproceedings{rossello_brain_2018,
	title = {Brain lesion segmentation using Convolutional Neuronal Networks},
	author = {Rosselló, Clara Bonnín},
	date = {2018},
	keywords = {Artificial neural network, Convolutional neural network, Adaptive sampling, biologic segmentation, Brain Neoplasms, Computer vision, Image processing, Loss function, Neural Network Simulation, Sampling (signal processing)},
	file = {Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\9H9XFZIM\\Rosselló - 2018 - Brain lesion segmentation using Convolutional Neur.pdf:application/pdf}
}

@article{playout_novel_2019,
	title = {A novel weakly supervised Multitask Architecture for Retinal Lesions Segmentation on Fundus Images},
	issn = {1558-254X},
	doi = {10.1109/TMI.2019.2906319},
	journaltitle = {{IEEE} transactions on medical imaging},
	shortjournal = {{IEEE} Trans Med Imaging},
	author = {Playout, Clement and Duval, Renaud and Cheriet, Farida},
	date = {2019-03-20},
	pmid = {30908197}
}

@online{noauthor_[1810.11654]_nodate,
	title = {[1810.11654] 3D {MRI} brain tumor segmentation using autoencoder regularization},
	url = {https://arxiv.org/abs/1810.11654},
	urldate = {2019-06-10},
	file = {[1810.11654] 3D MRI brain tumor segmentation using autoencoder regularization:C\:\\Users\\Sergey\\Zotero\\storage\\GE3B8QU5\\1810.html:text/html}
}

@article{BRATS_winning_2018,
	title = {3D {MRI} brain tumor segmentation using autoencoder regularization},
	url = {http://arxiv.org/abs/1810.11654},
	abstract = {Automated segmentation of brain tumors from 3D magnetic resonance images ({MRIs}) is necessary for the diagnosis, monitoring, and treatment planning of the disease. Manual delineation practices require anatomical knowledge, are expensive, time consuming and can be inaccurate due to human error. Here, we describe a semantic segmentation network for tumor subregion segmentation from 3D {MRIs} based on encoder-decoder architecture. Due to a limited training dataset size, a variational auto-encoder branch is added to reconstruct the input image itself in order to regularize the shared decoder and impose additional constraints on its layers. The current approach won 1st place in the {BraTS} 2018 challenge.},
	journaltitle = {{arXiv}:1810.11654 [cs, q-bio]},
	author = {Myronenko, Andriy},
	urldate = {2019-06-11},
	date = {2018-10-27},
	langid = {english},
	eprinttype = {arxiv},
	eprint = {1810.11654},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition},
	file = {Myronenko - 2018 - 3D MRI brain tumor segmentation using autoencoder .pdf:C\:\\Users\\Sergey\\Zotero\\storage\\R4IYWHPJ\\Myronenko - 2018 - 3D MRI brain tumor segmentation using autoencoder .pdf:application/pdf}
}

@article{white_matter,
	title = {Automatic method for white matter lesion segmentation based on T1-fluid-attenuated inversion recovery images},
	volume = {9},
	issn = {1751-9632},
	doi = {10.1049/iet-cvi.2014.0121},
	abstract = {The authors propose a fast and effective solution for automatic segmentation of white matter lesions by using T1 and fluid-attenuated inversion recovery ({FLAIR}) image modalities with no need for manual segmentation and atlas registration. Initially, a brain tissue segmentation method is used to segment the T1 image into cerebrospinal fluid ({CSF}), grey matter and white matter. Based on the obtained tissue segmentation results, the region of interest ({ROI}) of the {FLAIR} image is created by subtracting the {CSF} from the {FLAIR} image. Subsequently, the authors calculate the z-score of the intensities in the {ROI} and define a threshold to perform a preliminary identification of abnormalities from normal tissues. The abnormalities obtained at this stage are used as the prior knowledge for the modified level-set technique. The proposed level set method here is applied based on local Gaussian distribution to precisely detect the boundaries of the white matter lesions in the {ROI}. The level set method based on local Gaussian distribution fitting energy is robust to the intensity inhomogeneity of {MR} data and therefore capable of precisely extracting the boundaries of white matter lesions. Experimental analysis and quantitative comparisons with the peak-seeking and state-of-the-art white matter lesion segmentation ({WMLS}) techniques demonstrate that the algorithm is a stable and effective approach which significantly outperforms other trusted solutions for white matter lesion segmentation.},
	pages = {447--455},
	number = {4},
	journaltitle = {{IET} Computer Vision},
	author = {Zhan, T. and Zhan, Y. and Liu, Z. and Xiao, L. and Wei, Z.},
	date = {2015},
	keywords = {automatic white matter lesion segmentation, biological tissues, biomedical {MRI}, brain, brain tissue segmentation method, cerebrospinal fluid, Gaussian distribution, grey matter, image segmentation, local Gaussian distribution fitting energy, medical image processing, modified level-set technique, {MR} data intensity inhomogeneity, set theory, T1-fluid-attenuated inversion recovery image modality, white matter lesion boundary},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Sergey\\Zotero\\storage\\LVX357RF\\7172647.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\RD4A5K9X\\Zhan и др. - 2015 - Automatic method for white matter lesion segmentat.pdf:application/pdf}
}


@inproceedings{breast_tissue,
	title = {A weakly labeled approach for breast tissue segmentation and breast density estimation in digital mammography},
	doi = {10.1109/ISBI.2016.7493368},
	abstract = {Breast tissue segmentation is a fundamental task in digital mammography. Commonly, this segmentation is applied prior to breast density estimation. However, observations show a strong correlation between the segmentation parameters and the breast density, resulting in a chicken and egg problem. This paper presents a new method for breast segmentation, based on training with weakly labeled data, namely breast density categories. To this end, a Fuzzy-logic module is employed computing an adaptive parameter for segmentation. The suggested scheme consists of a feedback stage where a preliminary segmentation is used to allow extracting domain specific features from an early estimation of the tissue regions. Selected features are then fed into a fuzzy logic module to yield an updated threshold for segmentation. Our evaluation is based on 50 fibroglandular delineated images and on breast density classification, obtained on a large data set of 1243 full-field digital mammograms. The data set contained images from different devices. The proposed analysis provided an average Jaccard spatial similarity coefficient of 0.4 with improvement of this measure in 70\% of cases where the suggested module was applied. In breast density classification, average classification accuracy of 75\% was obtained, which significantly improved the baseline method (67.4\%). Major improvement is obtained in low breast densities where higher threshold levels rejects false positive regions. These results show a promise for the clinical application of this method in breast segmentation, without the need for laborious tissue annotation.},
	eventtitle = {2016 {IEEE} 13th International Symposium on Biomedical Imaging ({ISBI})},
	pages = {722--725},
	booktitle = {2016 {IEEE} 13th International Symposium on Biomedical Imaging ({ISBI})},
	author = {Ben-Ari, R. and Zlotnick, A. and Hashoul, S.},
	date = {2016-04},
	keywords = {Image segmentation, image segmentation, medical image processing, Adaptive parameter setting, average Jaccard spatial similarity coefficient, breast density, breast density classification, Breast tissue, breast tissue segmentation, Estimation, feature extraction, Feature extraction, fibroglandular delineated images, full-field digital mammograms, fuzzy logic, Fuzzy logic, fuzzy-logic module, image classification, mammography, Mammography, segmentation, weakly labeled approach},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Sergey\\Zotero\\storage\\28BAVKSZ\\7493368.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\X6PZ69NJ\\Ben-Ari и др. - 2016 - A weakly labeled approach for breast tissue segmen.pdf:application/pdf}
}

@article{zhu_mil,
  author    = {Wentao Zhu and
               Qi Lou and
               Yeeleng Scott Vang and
               Xiaohui Xie},
  title     = {Deep Multi-instance Networks with Sparse Label Assignment for Whole
               Mammogram Classification},
  journal   = {CoRR},
  volume    = {abs/1612.05968},
  year      = {2016},
  url       = {http://arxiv.org/abs/1612.05968},
  archivePrefix = {arXiv},
  eprint    = {1612.05968},
  timestamp = {Mon, 13 Aug 2018 16:47:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZhuLVX16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{prostate-cancer,
	title = {Biopsy-guided learning with deep convolutional neural networks for Prostate Cancer detection on multiparametric {MRI}},
	doi = {10.1109/ISBI.2017.7950602},
	eventtitle = {2017 {IEEE} 14th International Symposium on Biomedical Imaging ({ISBI} 2017)},
	pages = {642--645},
	booktitle = {2017 {IEEE} 14th International Symposium on Biomedical Imaging ({ISBI} 2017)},
	author = {Tsehay, Y. and Lay, N. and Wang, X. and Kwak, J. T. and Turkbey, B. and Choyke, P. and Pinto, P. and Wood, B. and Summers, R. M.},
	date = {2017-04},
	keywords = {biomedical {MRI}, Biopsy, Biopsy Database, biopsy-guided learning, cancer, computer-aided detection, Computer-Aided Detection, Databases, deep convolutional neural network, Holistically-nested Edge Detection, learning (artificial intelligence), Lesions, medical image processing, multiparametric {MRI}, neural nets, Principal component analysis, Prostate, prostate cancer detection, Prostate-{CAD}, Radiology, receiver operation characteristic curve, sensitivity analysis, Solid modeling, support vector machine, support vector machines, Training},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\Sergey\\Zotero\\storage\\R84SKTLJ\\7950602.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\Sergey\\Zotero\\storage\\LDR7H6P3\\Tsehay и др. - 2017 - Biopsy-guided learning with deep convolutional neu.pdf:application/pdf}
}